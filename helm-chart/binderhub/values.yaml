pdb:
  enabled: true
  maxUnavailable: 1
  minAvailable:

replicas: 1

resources:
  requests:
    cpu: 0.2
    memory: 512Mi

rbac:
  enabled: true

nodeSelector: {}
tolerations: []

image:
  name: quay.io/jupyterhub/k8s-binderhub
  tag: "set-by-chartpress"
  pullPolicy: ""
  pullSecrets: []

# registry here is only used to create docker config.json
registry:
  # key in 'auths' in docker config.json,
  # ~always the registry url
  url:
  # registry username+password
  username:
  password:

service:
  type: LoadBalancer
  labels: {}
  annotations:
    prometheus.io/scrape: "true"
  nodePort:
  loadBalancerIP:

config:
  # These c.BinderHub properties are referenced by the Helm chart
  BinderHub:
    # auth_enabled:
    base_url: /
    build_node_selector: {}
    # hub_url:
    # hub_url_local:
    use_registry: true
  KubernetesBuildExecutor: {}

extraConfig: {}

extraFiles: {}

extraPodSpec: {}

# Two bits of config need to be set to fully enable cors.
# config.BinderHub.cors_allow_origin controls the allowed origins for the
# binderhub api, and jupyterhub.hub.config.BinderSpawner.cors_allow_origin
# controls the allowed origins for the spawned user notebooks. You most
# likely want to set both of those to the same value.

jupyterhub:
  # Deprecated values, kept here so we can provide useful error messages
  custom:
    cors: {}
  cull:
    enabled: true
    users: false # see cull_users below
    timeout: 86400
    every: 3600
    maxAge: 604800
    concurrency: 4
  hub:
    config:
      JupyterHub:
        authenticator_class: nullauthenticator.NullAuthenticator
      BinderSpawner:
        auth_enabled: false
    loadRoles:
      binder:
        services:
          - binder
        scopes:
          - servers
          # admin:users is required in order to create a jupyterhub user for an
          # anonymous binderhub web-server visitor in non-authenticated
          # deployments, and read:users is required for authenticated
          # deployments to check the state of a jupyterhub user's running
          # servers before trying to launch.
          - admin:users
    extraConfig:
      0-binderspawnermixin: |
        """
        Helpers for creating BinderSpawners

        FIXME:
        This file is defined in binderhub/binderspawner_mixin.py
        and is copied to helm-chart/binderhub/values.yaml
        by ci/check_embedded_chart_code.py

        The BinderHub repo is just used as the distribution mechanism for this spawner,
        BinderHub itself doesn't require this code.

        Longer term options include:
        - Move BinderSpawnerMixin to a separate Python package and include it in the Z2JH Hub
          image
        - Override the Z2JH hub with a custom image built in this repository
        - Duplicate the code here and in binderhub/binderspawner_mixin.py
        """

        from tornado import web
        from traitlets import Bool, Unicode
        from traitlets.config import Configurable


        class BinderSpawnerMixin(Configurable):
            """
            Mixin to convert a JupyterHub container spawner to a BinderHub spawner

            Container spawner must support the following properties that will be set
            via spawn options:
            - image: Container image to launch
            - token: JupyterHub API token
            """

            def __init__(self, *args, **kwargs):
                # Is this right? Is it possible to having multiple inheritance with both
                # classes using traitlets?
                # https://stackoverflow.com/questions/9575409/calling-parent-class-init-with-multiple-inheritance-whats-the-right-way
                # https://github.com/ipython/traitlets/pull/175
                super().__init__(*args, **kwargs)

            auth_enabled = Bool(
                False,
                help="""
                Enable authenticated binderhub setup.

                Requires `jupyterhub-singleuser` to be available inside the repositories
                being built.
                """,
                config=True,
            )

            cors_allow_origin = Unicode(
                "",
                help="""
                Origins that can access the spawned notebooks.

                Sets the Access-Control-Allow-Origin header in the spawned
                notebooks. Set to '*' to allow any origin to access spawned
                notebook servers.

                See also BinderHub.cors_allow_origin in binderhub config
                for controlling CORS policy for the BinderHub API endpoint.
                """,
                config=True,
            )

            def get_args(self):
                if self.auth_enabled:
                    args = super().get_args()
                else:
                    args = [
                        "--ip=0.0.0.0",
                        f"--port={self.port}",
                        f"--NotebookApp.base_url={self.server.base_url}",
                        f"--NotebookApp.token={self.user_options['token']}",
                        "--NotebookApp.trust_xheaders=True",
                    ]
                    if self.default_url:
                        args.append(f"--NotebookApp.default_url={self.default_url}")

                    if self.cors_allow_origin:
                        args.append("--NotebookApp.allow_origin=" + self.cors_allow_origin)
                    # allow_origin=* doesn't properly allow cross-origin requests to single files
                    # see https://github.com/jupyter/notebook/pull/5898
                    if self.cors_allow_origin == "*":
                        args.append("--NotebookApp.allow_origin_pat=.*")
                    args += self.args
                    # ServerApp compatibility: duplicate NotebookApp args
                    for arg in list(args):
                        if arg.startswith("--NotebookApp."):
                            args.append(arg.replace("--NotebookApp.", "--ServerApp."))
                return args

            def start(self):
                if not self.auth_enabled:
                    if "token" not in self.user_options:
                        raise web.HTTPError(400, "token required")
                    if "image" not in self.user_options:
                        raise web.HTTPError(400, "image required")

                for k, v in self.user_options.items():
                    try:
                        o = getattr(self, k)
                        self.log.debug("BinderSpawner user_options %s: %s -> %s", k, o, v)
                        if isinstance(o, dict):
                            c = o.copy()
                            c.update(v)
                            v = c
                        elif isinstance(o, list):
                            if k in ('volumes','volume_mounts'):
                                # hack for volumes coming from I don't know where
                                c = [x for x in o if x['name'] == 'user-mount']
                                if len(c) > 1:
                                    c = c[:1]
                                #v = [y for y in v if y['name'] != 'user-mount']
                            else:
                                c = o.copy()
                            c.extend(v)
                            v = c
                        self.log.debug("BinderSpawner user_options %s: %s -> %s", k, o, v)
                        setattr(self, k, v)
                    except AttributeError:
                        pass
                return super().start()

      00-binder: |
        # image & token are set via spawn options
        from kubespawner import KubeSpawner

        class BinderSpawner(BinderSpawnerMixin, KubeSpawner):
            pass

        c.JupyterHub.spawner_class = BinderSpawner

      cull_users: |
        c.JupyterHub.services.append({
          'name': 'cull-idle-users',
          'admin': True,
          'command': ['python3', '-m', 'jupyterhub_idle_culler',
            '--url=http://127.0.0.1:8081/hub/hub/api',
            '--timeout=2500000',
            '--cull-every=86400',
            '--concurrency=4',
            '--cull-users'
          ]})

      monitor: |
        from jupyterhub.handlers import BaseHandler
        import prometheus_client
        from tornado import web
        import ipaddress
        import datetime
        from traitlets.config import Configurable
        from traitlets import Set
        from kubespawner.clients import shared_client
        from kubespawner import KubeSpawner
        from kubernetes_asyncio.client import api_client
        from kubernetes_asyncio.client.exceptions import ApiException
        try:
            from kubernetes_asyncio.dynamic import DynamicClient
            from kubernetes_asyncio.dynamic.exceptions import ResourceNotFoundError
        except ImportError:
            DynamicClient = None
            ResourceNotFoundError = TypeError
        #from kubernetes_asyncio.utils import parse_quantity

        # https://github.com/kubernetes-client/python/blob/master/kubernetes/utils/quantity.py
        from decimal import Decimal, InvalidOperation

        def parse_quantity(quantity):
            """
            Parse kubernetes canonical form quantity like 200Mi to a decimal number.
            Supported SI suffixes:
            base1024: Ki | Mi | Gi | Ti | Pi | Ei
            base1000: n | u | m | "" | k | M | G | T | P | E

            See https://github.com/kubernetes/apimachinery/blob/master/pkg/api/resource/quantity.go

            Input:
            quantity: string. kubernetes canonical form quantity

            Returns:
            Decimal

            Raises:
            ValueError on invalid or unknown input
            """
            if isinstance(quantity, (int, float, Decimal)):
                return Decimal(quantity)

            exponents = {"n": -3, "u": -2, "m": -1, "K": 1, "k": 1, "M": 2,
                         "G": 3, "T": 4, "P": 5, "E": 6}

            quantity = str(quantity)
            number = quantity
            suffix = None
            if len(quantity) >= 2 and quantity[-1] == "i":
                if quantity[-2] in exponents:
                    number = quantity[:-2]
                    suffix = quantity[-2:]
            elif len(quantity) >= 1 and quantity[-1] in exponents:
                number = quantity[:-1]
                suffix = quantity[-1:]

            try:
                number = Decimal(number)
            except InvalidOperation:
                raise ValueError("Invalid number format: {}".format(number))

            if suffix is None:
                return number

            if suffix.endswith("i"):
                base = 1024
            elif len(suffix) == 1:
                base = 1000
            else:
                raise ValueError("{} has unknown suffix".format(quantity))

            # handle SI inconsistency
            if suffix == "ki":
                raise ValueError("{} has unknown suffix".format(quantity))

            if suffix[0] not in exponents:
                raise ValueError("{} has unknown suffix".format(quantity))

            exponent = Decimal(exponents[suffix[0]])
            return number * (base ** exponent)

        class Monitor(Configurable):
            allowed_monitor_ips = Set(config=True)
            mets = []
            
            async def load(self):
                try:
                    pods = KubeSpawner.reflectors[('pods','binder')].pods
                except KeyError:
                    return
                except AttributeError:
                    return
                async with api_client.ApiClient() as apic:
                    try:
                        client = await DynamicClient(apic)
                        api = await client.resources.get(api_version='metrics.k8s.io/v1beta1', kind='PodMetrics')
                    except ResourceNotFoundError:
                        api = None

                    l = ['user','specuser','specproj']
                    run = prometheus_client.metrics_core.GaugeMetricFamily('binder_running_servers', 'Running binderhub jupyter servers', labels=l)
                    mets = [run]
                    resources = {'cpu':{},'memory':{},'nvidia.com/gpu':{}}
                    for r,m in resources.items():
                        sr = r.rsplit('/', 1)[-1]
                        for t in ('request','limit'):
                            m[t] = prometheus_client.metrics_core.GaugeMetricFamily('binder_running_server_'+sr+'_'+t, 'Running binderhub jupyter servers '+r+' '+t, labels=l)
                            mets.append(m[t])
                        if api:
                            m['usage'] = prometheus_client.metrics_core.GaugeMetricFamily('binder_running_server_'+sr, 'Running binderhub jupyter servers '+r+' usage', labels=l)
                            mets.append(m['usage'])

                    for pod in pods.values():
                        # assuming (max) one per user
                        meta = pod['metadata']
                        annot = meta['annotations']
                        l = []
                        try:
                            l.append(annot['hub.jupyter.org/username'])
                            l.extend(annot['binder.jupyter.org/spec'].split('/', 1))
                        except KeyError:
                            pass
                        run.add_metric(l, 1)
                        for r,m in resources.items():
                            for t in ('request','limit'):
                                m[t].add_metric(l, sum(parse_quantity(c.get('resources',{}).get(t+'s',{}).get(r,0)) for c in pod['spec']['containers']))

                        if not api:
                            continue
                        try:
                            res = await api.get(namespace = meta['namespace'], name = meta['name'])
                        except ApiException as e:
                            continue
                        ts = res.timestamp
                        if ts is None:
                            continue
                        if ts.endswith('Z'):
                            ts = ts[:-1]+'+00:00'
                        ts = datetime.datetime.fromisoformat(ts).timestamp()
                        for r,m in resources.items():
                            v = (getattr(c.usage,r,None) for c in res.containers)
                            v = [parse_quantity(x) for x in v if x is not None]
                            if v:
                                m['usage'].add_metric(l, sum(v), timestamp=ts)

                    self.mets = mets

            def collect(self):
                return self.mets

        class MonitorHandler(BaseHandler):
            async def get(self):
                monitor = Monitor(config = self.config)
                allowed = list(map(ipaddress.ip_network, monitor.allowed_monitor_ips))

                if allowed:
                    ip = ipaddress.ip_address(self.request.remote_ip)
                    if not any(ip in a for a in allowed):
                        raise web.HTTPError(403)

                await monitor.load()

                self.set_header('Content-Type', prometheus_client.CONTENT_TYPE_LATEST)
                self.write(prometheus_client.generate_latest(prometheus_client.REGISTRY))
                registry = prometheus_client.CollectorRegistry(auto_describe=True)
                registry.register(monitor)
                self.write(prometheus_client.generate_latest(registry))

        c.JupyterHub.extra_handlers.append((r'/monitor$', MonitorHandler))

    services:
      binder:
        display: false
  singleuser:
    # start jupyterlab server *if available*
    # fallback on jupyter-notebook
    cmd:
      - python3
      - "-c"
      - |
        import os
        import sys

        try:
            import jupyterlab
            import jupyterlab.labapp
            major = int(jupyterlab.__version__.split(".", 1)[0])
        except Exception as e:
            print("Failed to import jupyterlab: {e}", file=sys.stderr)
            have_lab = False
        else:
            have_lab = major >= 3

        if have_lab:
            # technically, we could accept another jupyter-server-based frontend
            print("Launching jupyter-lab", file=sys.stderr)
            exe = "jupyter-lab"
        else:
            print("jupyter-lab not found, launching jupyter-notebook", file=sys.stderr)
            exe = "jupyter-notebook"

        # launch the notebook server
        os.execvp(exe, sys.argv)
    events: true
    storage:
      type: none
    memory:
      guarantee:
  prePuller:
    hook:
      enabled: false
    continuous:
      enabled: false

deployment:
  readinessProbe:
    enabled: true
    initialDelaySeconds: 0
    periodSeconds: 5
    failureThreshold: 1000 # we rely on the liveness probe to resolve issues if needed
    timeoutSeconds: 3
  livenessProbe:
    enabled: true
    initialDelaySeconds: 10
    periodSeconds: 5
    failureThreshold: 3
    timeoutSeconds: 10
  labels: {}

imageBuilderType: "host"

dind:
  initContainers: []
  daemonset:
    image:
      name: docker.io/library/docker
      tag: "27.1.1-dind" # ref: https://hub.docker.com/_/docker/tags
      pullPolicy: ""
      pullSecrets: []
    # Additional command line arguments to pass to dockerd
    extraArgs: []
    lifecycle: {}
    extraVolumes: []
    extraVolumeMounts: []
  storageDriver: overlay2
  resources: {}
  hostSocketDir: /var/run/dind
  hostLibDir: /var/lib/dind
  hostSocketName: docker.sock

# Podman in Kubernetes
pink:
  initContainers: []
  daemonset:
    image:
      name: quay.io/podman/stable
      tag: "v5.1.2" # ref: https://quay.io/repository/podman/stable
      pullPolicy: ""
      pullSecrets: []
    lifecycle: {}
    extraVolumes: []
    extraVolumeMounts: []
  resources: {}
  hostStorageDir: /var/lib/pink/storage
  hostSocketDir: /var/run/pink
  hostSocketName: podman.sock

imageCleaner:
  enabled: true
  image:
    name: quay.io/jupyterhub/docker-image-cleaner
    tag: "1.0.0-beta.3"
    pullPolicy: ""
    pullSecrets: []
  # delete an image at most every 5 seconds
  delay: 5
  # Interpret threshold values as percentage or bytes
  imageGCThresholdType: "relative"
  # when 80% of inodes are used,
  # cull images until it drops below 60%
  imageGCThresholdHigh: 80
  imageGCThresholdLow: 60
  # cull images on the host docker as well as dind
  # configuration to use if `imageBuilderType: host` is configured
  host:
    dockerSocket: /var/run/docker.sock
    dockerLibDir: /var/lib/docker
  extraTolerations: []

ingress:
  enabled: false
  https:
    enabled: false
    type: kube-lego
  hosts: []
  ingressClassName:
  annotations:
    {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  pathSuffix:
    # Suffix added to Ingress's routing path pattern.
    # Specify `*` if your ingress matches path by glob pattern.
  pathType: Prefix
  tls:
    []
    # Secrets must be manually created in the namespace.
    # - secretName: chart-example-tls
    #   hosts:
    #     - chart-example.local

initContainers: []
lifecycle: {}
extraVolumes: []
extraVolumeMounts: []
extraEnv: {}
podAnnotations: {}

# Deprecated values, kept here so we can provide useful error messages
cors: {}

global: {}
