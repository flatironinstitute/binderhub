pdb:
  enabled: true
  minAvailable: 1

replicas: 1

resources:
  requests:
    cpu: 0.2
    memory: 512Mi

rbac:
  enabled: true

nodeSelector: {}

image:
  name: jupyterhub/k8s-binderhub
  tag: 'local'

# registry here is only used to create docker config.json
registry:
  # key in 'auths' in docker config.json,
  # ~always the registry url
  url:
  # registry username+password
  username:
  password:

service:
  type: LoadBalancer
  labels: {}
  annotations:
    prometheus.io/scrape: 'true'
  nodePort:

config:
  BinderHub: {}

extraConfig: {}

# have to set cors.allowOrigin twice:
# once in top-level cors.allowOrigin,
# and again in jupyterhub.hub.extraConfigMap.cors.allowOrigin

# Using YAML anchors, `&cors` for the first appearance and `*cors` for subsequent
# appearances, allows us to remove redundancy in this (BinderHub) `values.yaml`.
# The anchors do not extend beyond this file.
# As such, users must set `cors` separately for their own user `values.yaml` for notebooks.
# `cors` will be set separately in the user `values.yaml` and binderhub`values.yaml`.
# The same anchor pattern (`&cors`, `*cors`) can be used in the user `values.yaml`.

cors: &cors
  allowOrigin:

jupyterhub:
  cull:
    enabled: true
    users: false # see cull_users below
    timeout: 86400
    every: 3600
    maxAge: 604800
    concurrency: 4
  custom:
    cors: *cors
    binderauth_enabled: false
  rbac:
    enabled: true
  hub:
    config:
      JupyterHub:
        authenticator_class: nullauthenticator.NullAuthenticator
    extraConfig:
      00-binder: |
        from tornado import web

        # get custom config from values.custom
        import z2jh
        cors = z2jh.get_config('custom.cors', {})
        auth_enabled = z2jh.get_config('custom.binderauth_enabled', False)

        # image & token are set via spawn options
        from kubespawner import KubeSpawner

        class BinderSpawner(KubeSpawner):
            def get_args(self):
                if auth_enabled:
                    args = super().get_args()
                else:
                    args = [
                        '--ip=0.0.0.0',
                        '--port=%i' % self.port,
                        '--NotebookApp.base_url=%s' % self.server.base_url,
                        '--NotebookApp.token=%s' % self.user_options['token'],
                        '--NotebookApp.trust_xheaders=True',
                    ]
                    allow_origin = cors.get('allowOrigin')
                    if allow_origin:
                        args.append('--NotebookApp.allow_origin=' + allow_origin)
                    # allow_origin=* doesn't properly allow cross-origin requests to single files
                    # see https://github.com/jupyter/notebook/pull/5898
                    if allow_origin == '*':
                        args.append('--NotebookApp.allow_origin_pat=.*')
                    args += self.args
                return args

            def start(self):
                if not auth_enabled:
                    if 'token' not in self.user_options:
                        raise web.HTTPError(400, "token required")
                    if 'image' not in self.user_options:
                        raise web.HTTPError(400, "image required")

                for k, v in self.user_options.items():
                    try:
                        o = getattr(self, k)
                        self.log.debug("BinderSpawner user_options %s: %s -> %s", k, o, v)
                        if isinstance(o, dict):
                            c = o.copy()
                            c.update(v)
                            v = c
                        elif isinstance(o, list):
                            if k in ('volumes','volume_mounts'):
                                # hack for volumes coming from I don't know where
                                c = [x for x in o if x['name'] == 'user-mount']
                                if len(c) > 1:
                                    c = c[:1]
                                #v = [y for y in v if y['name'] != 'user-mount']
                            else:
                                c = o.copy()
                            c.extend(v)
                            v = c
                        self.log.debug("BinderSpawner user_options %s: %s -> %s", k, o, v)
                        setattr(self, k, v)
                    except AttributeError:
                        pass
                return super().start()

        c.JupyterHub.spawner_class = BinderSpawner

      cull_users: |
        c.JupyterHub.services.append({
          'name': 'cull-idle-users',
          'admin': True,
          'command': ['python3', '-m', 'jupyterhub_idle_culler',
            '--url=http://127.0.0.1:8081/hub/hub/api',
            '--timeout=604800',
            '--cull-every=86400',
            '--concurrency=4',
            '--cull-users'
          ]})

      delete_user_pvc: |
        import string
        import escapism
        import oauthenticator
        import kubernetes.client
        import tornado.concurrent
        import concurrent.futures

        pvc_name_template = get_config('singleuser.storage.dynamic.pvcNameTemplate')
        pvc_namespace = os.environ.get('POD_NAMESPACE', 'default')

        class BinderAuthenticator(oauthenticator.GoogleOAuthenticator):
            executor = concurrent.futures.ThreadPoolExecutor(1)

            @tornado.concurrent.run_on_executor
            def delete_pvc(self, user):
                safe_chars = set(string.ascii_lowercase + string.digits)
                legacy_escaped_username = ''.join([s if s in safe_chars else '-' for s in user.name.lower()])
                safe_username = escapism.escape(user.name, safe=safe_chars, escape_char='-').lower()
                name = pvc_name_template.format(
                    userid=user.id,
                    username=safe_username,
                    unescaped_username=user.name,
                    legacy_escape_username=legacy_escaped_username,
                    servername='',
                    unescaped_servername=''
                )
                try:
                    kubernetes.client.CoreV1Api().delete_namespaced_persistent_volume_claim(name, pvc_namespace, body=kubernetes.client.V1DeleteOptions())
                except kubernetes.client.rest.ApiException as e:
                    if e.status != 404:
                      self.log.warn("Error deleting user PVC %s: %s", name, e)

            def delete_user(self, user):
                self.delete_pvc(user)
                return super().delete_user(user)

        c.JupyterHub.authenticator_class = BinderAuthenticator

      monitor: |
        from jupyterhub.handlers import BaseHandler
        import prometheus_client
        from tornado import web
        import ipaddress
        import datetime
        from kubespawner.clients import shared_client
        from kubespawner import KubeSpawner
        from kubernetes.dynamic import DynamicClient
        from kubernetes.dynamic.exceptions import ResourceNotFoundError
        from kubernetes.client.exceptions import ApiException
        from kubernetes.utils import parse_quantity

        import z2jh
        allowed = list(map(ipaddress.ip_network, z2jh.get_config('custom.allowed_monitor_ips', [])))

        class Monitor(object):
            def collect(self):
                pods = KubeSpawner.reflectors['pods']
                if not pods: return []
                try:
                    api = DynamicClient(shared_client('ApiClient')).resources.get(api_version='metrics.k8s.io/v1beta1', kind='PodMetrics')
                except ResourceNotFoundError:
                    api = None

                l = ['user','specuser','specproj']
                run = prometheus_client.metrics_core.GaugeMetricFamily('binder_running_servers', 'Running binderhub jupyter servers', labels=l)
                mets = [run]
                resources = {'cpu':{},'memory':{}}
                for r,m in resources.items():
                    for t in ('request','limit'):
                        m[t] = prometheus_client.metrics_core.GaugeMetricFamily('binder_running_server_'+r+'_'+t, 'Running binderhub jupyter servers '+r+' '+t, labels=l)
                        mets.append(m[t])
                    if api:
                        m['usage'] = prometheus_client.metrics_core.GaugeMetricFamily('binder_running_server_'+r, 'Running binderhub jupyter servers '+r+' usage', labels=l)
                        mets.append(m['usage'])

                for pod in pods.pods.values():
                    # assuming (max) one per user
                    meta = pod['metadata']
                    annot = meta['annotations']
                    l = []
                    try:
                        l.append(annot['hub.jupyter.org/username'])
                        l.extend(annot['binder.jupyter.org/spec'].split('/', 1))
                    except KeyError:
                        pass
                    run.add_metric(l, 1)
                    for r,m in resources.items():
                        for t in ('request','limit'):
                            m[t].add_metric(l, sum(parse_quantity(c.get('resources',{}).get(t+'s',{}).get(r,0)) for c in pod['spec']['containers']))

                    if not api:
                        continue
                    try:
                        res = api.get(namespace = meta['namespace'], name = meta['name'])
                    except ApiException as e:
                        continue
                    ts = res.timestamp
                    if ts.endswith('Z'):
                        ts = ts[:-1]+'+00:00'
                    ts = datetime.datetime.fromisoformat(ts).timestamp()
                    for r,m in resources.items():
                        m['usage'].add_metric(l, sum(parse_quantity(getattr(c.usage,r)) for c in res.containers), timestamp=ts)

                return mets

        registry = prometheus_client.CollectorRegistry(auto_describe=True)
        registry.register(Monitor())

        class MonitorHandler(BaseHandler):
            async def get(self):
                if allowed:
                    ip = ipaddress.ip_address(self.request.remote_ip)
                    if not any(ip in a for a in allowed):
                        raise web.HTTPError(403)
                self.set_header('Content-Type', prometheus_client.CONTENT_TYPE_LATEST)
                self.write(prometheus_client.generate_latest(prometheus_client.REGISTRY))
                self.write(prometheus_client.generate_latest(registry))

        c.JupyterHub.extra_handlers.append((r'/monitor$', MonitorHandler))

    services:
      binder:
        admin: true
        apiToken:
  singleuser:
    # start jupyter notebook
    cmd: jupyter-notebook
    events: false
    storage:
      type: none
    memory:
      guarantee:
  prePuller:
    hook:
      enabled: false
    continuous:
      enabled: false

deployment:
  readinessProbe:
    enabled: true
    initialDelaySeconds: 0
    periodSeconds: 5
    failureThreshold: 1000  # we rely on the liveness probe to resolve issues if needed
    timeoutSeconds: 3
  livenessProbe:
    enabled: true
    initialDelaySeconds: 10
    periodSeconds: 5
    failureThreshold: 3
    timeoutSeconds: 10
  labels: {}

dind:
  enabled: false
  initContainers: []
  daemonset:
    image:
      name: docker
      tag: 19.03.5-dind
    # Additional command line arguments to pass to dockerd
    extraArgs: []
    lifecycle: {}
    extraVolumes: []
    extraVolumeMounts: []
  storageDriver: overlay2
  resources: {}
  hostSocketDir: /var/run/dind
  hostLibDir: /var/lib/dind

imageCleaner:
  enabled: true
  image:
    name: jupyterhub/k8s-image-cleaner
    tag: 'local'
  # delete an image at most every 5 seconds
  delay: 5
  # Interpret threshold values as percentage or bytes
  imageGCThresholdType: "relative"
  # when 80% of inodes are used,
  # cull images until it drops below 60%
  imageGCThresholdHigh: 80
  imageGCThresholdLow: 60
  # cull images on the host docker as well as dind
  host:
    enabled: true
    dockerSocket: /var/run/docker.sock
    dockerLibDir: /var/lib/docker

ingress:
  enabled: false
  https:
    enabled: false
    type: kube-lego
  hosts:
    - chart-example.local
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  pathSuffix: ''
    # Suffix added to Ingress's routing path pattern.
    # Specify `*` if your ingress matches path by glob pattern.
  tls: []
    # Secrets must be manually created in the namespace.
    # - secretName: chart-example-tls
    #   hosts:
    #     - chart-example.local

initContainers: []
lifecycle: {}
extraVolumes: []
extraVolumeMounts: []
extraEnv: {}
podAnnotations: {}
