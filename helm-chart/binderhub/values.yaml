pdb:
  enabled: true
  maxUnavailable: 1
  minAvailable:

replicas: 1

resources:
  requests:
    cpu: 0.2
    memory: 512Mi

rbac:
  enabled: true

nodeSelector: {}

image:
  name: jupyterhub/k8s-binderhub
  tag: 'local'

# registry here is only used to create docker config.json
registry:
  # key in 'auths' in docker config.json,
  # ~always the registry url
  url:
  # registry username+password
  username:
  password:

service:
  type: LoadBalancer
  labels: {}
  annotations:
    prometheus.io/scrape: 'true'
  nodePort:
  loadBalancerIP:

config:
  BinderHub: {}

extraConfig: {}

# Two bits of config need to be set to fully enable cors.
# config.BinderHub.cors_allow_origin controls the allowed origins for the
# binderhub api, and jupyterhub.hub.config.BinderSpawner.cors_allow_origin
# controls the allowed origins for the spawned user notebooks. You most
# likely want to set both of those to the same value.

jupyterhub:
  # Deprecated values, kept here so we can provide useful error messages
  custom:
    cors: {}
  cull:
    enabled: true
    users: false # see cull_users below
    timeout: 86400
    every: 3600
    maxAge: 604800
    concurrency: 4
  rbac:
    enabled: true
  hub:
    config:
      JupyterHub:
        authenticator_class: nullauthenticator.NullAuthenticator
      BinderSpawner:
        auth_enabled: false
    extraConfig:
      0-binderspawnermixin: |
        """
        Helpers for creating BinderSpawners

        FIXME:
        This file is defined in helm-chart/binderhub/values.yaml and is copied to
        binderhub/binderspawner_mixin.py by setup.py so that it can be used by other JupyterHub
        container spawners.

        The BinderHub repo is just used as the distribution mechanism for this spawner, BinderHub
        itself doesn't require this code.

        Longer term options include:
        - Move BinderSpawnerMixin to a separate Python package and include it in the Z2JH Hub
          image
        - Override the Z2JH hub with a custom image built in this repository
        - Duplicate the code here and in binderhub/binderspawner_mixin.py
        """
        from tornado import web
        from traitlets.config import Configurable
        from traitlets import Bool, Unicode


        class BinderSpawnerMixin(Configurable):
            """
            Mixin to convert a JupyterHub container spawner to a BinderHub spawner

            Container spawner must support the following properties that will be set
            via spawn options:
            - image: Container image to launch
            - token: JupyterHub API token
            """

            def __init__(self, *args, **kwargs):
                # Is this right? Is it possible to having multiple inheritance with both
                # classes using traitlets?
                # https://stackoverflow.com/questions/9575409/calling-parent-class-init-with-multiple-inheritance-whats-the-right-way
                # https://github.com/ipython/traitlets/pull/175
                super(BinderSpawnerMixin, self).__init__(*args, **kwargs)

            auth_enabled = Bool(
                False,
                help="""
                Enable authenticated binderhub setup.

                Requires `jupyterhub-singleuser` to be available inside the repositories
                being built.
                """,
                config=True
            )

            cors_allow_origin = Unicode(
                "",
                help="""
                Origins that can access the spawned notebooks.

                Sets the Access-Control-Allow-Origin header in the spawned
                notebooks. Set to '*' to allow any origin to access spawned
                notebook servers.

                See also BinderHub.cors_allow_origin in binderhub config
                for controlling CORS policy for the BinderHub API endpoint.
                """,
                config=True
            )

            def get_args(self):
                if self.auth_enabled:
                    args = super().get_args()
                else:
                    args = [
                        '--ip=0.0.0.0',
                        f'--port={self.port}',
                        f'--NotebookApp.base_url={self.server.base_url}',
                        f"--NotebookApp.token={self.user_options['token']}",
                        '--NotebookApp.trust_xheaders=True',
                    ]
                    if self.default_url:
                        args.append(f'--NotebookApp.default_url={self.default_url}')

                    if self.cors_allow_origin:
                        args.append('--NotebookApp.allow_origin=' + self.cors_allow_origin)
                    # allow_origin=* doesn't properly allow cross-origin requests to single files
                    # see https://github.com/jupyter/notebook/pull/5898
                    if self.cors_allow_origin == '*':
                        args.append('--NotebookApp.allow_origin_pat=.*')
                    args += self.args
                return args

            def start(self):
                if not self.auth_enabled:
                    if 'token' not in self.user_options:
                        raise web.HTTPError(400, "token required")
                    if 'image' not in self.user_options:
                        raise web.HTTPError(400, "image required")

                for k, v in self.user_options.items():
                    try:
                        o = getattr(self, k)
                        self.log.debug("BinderSpawner user_options %s: %s -> %s", k, o, v)
                        if isinstance(o, dict):
                            c = o.copy()
                            c.update(v)
                            v = c
                        elif isinstance(o, list):
                            if k in ('volumes','volume_mounts'):
                                # hack for volumes coming from I don't know where
                                c = [x for x in o if x['name'] == 'user-mount']
                                if len(c) > 1:
                                    c = c[:1]
                                #v = [y for y in v if y['name'] != 'user-mount']
                            else:
                                c = o.copy()
                            c.extend(v)
                            v = c
                        self.log.debug("BinderSpawner user_options %s: %s -> %s", k, o, v)
                        setattr(self, k, v)
                    except AttributeError:
                        pass
                return super().start()

      00-binder: |
        # image & token are set via spawn options
        from kubespawner import KubeSpawner

        class BinderSpawner(BinderSpawnerMixin, KubeSpawner):
            pass

        c.JupyterHub.spawner_class = BinderSpawner

      cull_users: |
        c.JupyterHub.services.append({
          'name': 'cull-idle-users',
          'admin': True,
          'command': ['python3', '-m', 'jupyterhub_idle_culler',
            '--url=http://127.0.0.1:8081/hub/hub/api',
            '--timeout=604800',
            '--cull-every=86400',
            '--concurrency=4',
            '--cull-users'
          ]})

      delete_user_pvc: |
        import string
        import escapism
        import oauthenticator
        import kubernetes.client
        import tornado.concurrent
        import concurrent.futures

        pvc_name_template = get_config('singleuser.storage.dynamic.pvcNameTemplate')
        pvc_namespace = os.environ.get('POD_NAMESPACE', 'default')

        class BinderAuthenticator(oauthenticator.GoogleOAuthenticator):
            executor = concurrent.futures.ThreadPoolExecutor(1)

            @tornado.concurrent.run_on_executor
            def delete_pvc(self, user):
                safe_chars = set(string.ascii_lowercase + string.digits)
                legacy_escaped_username = ''.join([s if s in safe_chars else '-' for s in user.name.lower()])
                safe_username = escapism.escape(user.name, safe=safe_chars, escape_char='-').lower()
                name = pvc_name_template.format(
                    userid=user.id,
                    username=safe_username,
                    unescaped_username=user.name,
                    legacy_escape_username=legacy_escaped_username,
                    servername='',
                    unescaped_servername=''
                )
                try:
                    kubernetes.client.CoreV1Api().delete_namespaced_persistent_volume_claim(name, pvc_namespace, body=kubernetes.client.V1DeleteOptions())
                except kubernetes.client.rest.ApiException as e:
                    if e.status != 404:
                      self.log.warn("Error deleting user PVC %s: %s", name, e)

            def delete_user(self, user):
                self.delete_pvc(user)
                return super().delete_user(user)

        c.JupyterHub.authenticator_class = BinderAuthenticator

      monitor: |
        from jupyterhub.handlers import BaseHandler
        import prometheus_client
        from tornado import web
        import ipaddress
        import datetime
        from kubespawner.clients import shared_client
        from kubespawner import KubeSpawner
        from kubernetes.dynamic import DynamicClient
        from kubernetes.dynamic.exceptions import ResourceNotFoundError
        from kubernetes.client.exceptions import ApiException
        from kubernetes.utils import parse_quantity

        import z2jh
        allowed = list(map(ipaddress.ip_network, z2jh.get_config('custom.allowed_monitor_ips', [])))

        class Monitor(object):
            def collect(self):
                pods = KubeSpawner.reflectors['pods']
                if not pods: return []
                try:
                    api = DynamicClient(shared_client('ApiClient')).resources.get(api_version='metrics.k8s.io/v1beta1', kind='PodMetrics')
                except ResourceNotFoundError:
                    api = None

                l = ['user','specuser','specproj']
                run = prometheus_client.metrics_core.GaugeMetricFamily('binder_running_servers', 'Running binderhub jupyter servers', labels=l)
                mets = [run]
                resources = {'cpu':{},'memory':{}}
                for r,m in resources.items():
                    for t in ('request','limit'):
                        m[t] = prometheus_client.metrics_core.GaugeMetricFamily('binder_running_server_'+r+'_'+t, 'Running binderhub jupyter servers '+r+' '+t, labels=l)
                        mets.append(m[t])
                    if api:
                        m['usage'] = prometheus_client.metrics_core.GaugeMetricFamily('binder_running_server_'+r, 'Running binderhub jupyter servers '+r+' usage', labels=l)
                        mets.append(m['usage'])

                for pod in pods.pods.values():
                    # assuming (max) one per user
                    meta = pod['metadata']
                    annot = meta['annotations']
                    l = []
                    try:
                        l.append(annot['hub.jupyter.org/username'])
                        l.extend(annot['binder.jupyter.org/spec'].split('/', 1))
                    except KeyError:
                        pass
                    run.add_metric(l, 1)
                    for r,m in resources.items():
                        for t in ('request','limit'):
                            m[t].add_metric(l, sum(parse_quantity(c.get('resources',{}).get(t+'s',{}).get(r,0)) for c in pod['spec']['containers']))

                    if not api:
                        continue
                    try:
                        res = api.get(namespace = meta['namespace'], name = meta['name'])
                    except ApiException as e:
                        continue
                    ts = res.timestamp
                    if ts.endswith('Z'):
                        ts = ts[:-1]+'+00:00'
                    ts = datetime.datetime.fromisoformat(ts).timestamp()
                    for r,m in resources.items():
                        m['usage'].add_metric(l, sum(parse_quantity(getattr(c.usage,r)) for c in res.containers), timestamp=ts)

                return mets

        registry = prometheus_client.CollectorRegistry(auto_describe=True)
        registry.register(Monitor())

        class MonitorHandler(BaseHandler):
            async def get(self):
                if allowed:
                    ip = ipaddress.ip_address(self.request.remote_ip)
                    if not any(ip in a for a in allowed):
                        raise web.HTTPError(403)
                self.set_header('Content-Type', prometheus_client.CONTENT_TYPE_LATEST)
                self.write(prometheus_client.generate_latest(prometheus_client.REGISTRY))
                self.write(prometheus_client.generate_latest(registry))

        c.JupyterHub.extra_handlers.append((r'/monitor$', MonitorHandler))

    services:
      binder:
        admin: true
        apiToken:
  singleuser:
    # start notebook server with lab ui as default
    # *if available*
    cmd:
      - python3
      - "-c"
      - |
        import os
        import sys

        try:
            import jupyterlab
            major = int(jupyterlab.__version__.split(".", 1)[0])
        except Exception:
            have_lab = False
        else:
            have_lab = major >= 3

        if have_lab and "NotebookApp.default_url" not in " ".join(sys.argv):
            # if recent-enough lab is available, make it the default UI
            sys.argv.insert(1, "--NotebookApp.default_url=/lab/")

        # launch the notebook server
        os.execvp("jupyter-notebook", sys.argv)
    events: true
    storage:
      type: none
    memory:
      guarantee:
  prePuller:
    hook:
      enabled: false
    continuous:
      enabled: false

deployment:
  readinessProbe:
    enabled: true
    initialDelaySeconds: 0
    periodSeconds: 5
    failureThreshold: 1000  # we rely on the liveness probe to resolve issues if needed
    timeoutSeconds: 3
  livenessProbe:
    enabled: true
    initialDelaySeconds: 10
    periodSeconds: 5
    failureThreshold: 3
    timeoutSeconds: 10
  labels: {}

dind:
  enabled: false
  initContainers: []
  daemonset:
    image:
      name: docker
      tag: 19.03.5-dind
    # Additional command line arguments to pass to dockerd
    extraArgs: []
    lifecycle: {}
    extraVolumes: []
    extraVolumeMounts: []
  storageDriver: overlay2
  resources: {}
  hostSocketDir: /var/run/dind
  hostLibDir: /var/lib/dind

imageCleaner:
  enabled: true
  image:
    name: quay.io/jupyterhub/docker-image-cleaner
    tag: 1.0.0-alpha.2
  # delete an image at most every 5 seconds
  delay: 5
  # Interpret threshold values as percentage or bytes
  imageGCThresholdType: "relative"
  # when 80% of inodes are used,
  # cull images until it drops below 60%
  imageGCThresholdHigh: 80
  imageGCThresholdLow: 60
  # cull images on the host docker as well as dind
  host:
    enabled: true
    dockerSocket: /var/run/docker.sock
    dockerLibDir: /var/lib/docker

ingress:
  enabled: false
  https:
    enabled: false
    type: kube-lego
  hosts: []
  ingressClassName:
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  pathSuffix:
    # Suffix added to Ingress's routing path pattern.
    # Specify `*` if your ingress matches path by glob pattern.
  pathType: Prefix
  tls: []
    # Secrets must be manually created in the namespace.
    # - secretName: chart-example-tls
    #   hosts:
    #     - chart-example.local

initContainers: []
lifecycle: {}
extraVolumes: []
extraVolumeMounts: []
extraEnv: {}
podAnnotations: {}

# Deprecated values, kept here so we can provide useful error messages
cors: {}
